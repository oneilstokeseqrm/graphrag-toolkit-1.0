# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: Apache-2.0

import concurrent.futures
import re
import logging

from pydantic import Field
from typing import List, Optional

from llama_index.core.postprocessor.types import BaseNodePostprocessor
from llama_index.core.schema import NodeWithScore, QueryBundle, TextNode
from llama_index.core.prompts import ChatPromptTemplate
from llama_index.core.llms import ChatMessage, MessageRole

from graphrag_toolkit.lexical_graph import GraphRAGConfig
from graphrag_toolkit.lexical_graph.utils import LLMCache, LLMCacheType
from graphrag_toolkit.lexical_graph.retrieval.prompts import ENHANCE_STATEMENT_SYSTEM_PROMPT, ENHANCE_STATEMENT_USER_PROMPT

logger = logging.getLogger(__name__)

class StatementEnhancementPostProcessor(BaseNodePostprocessor):
    """
    Post-processes nodes to enhance their statements using provided language model and templates.

    The `StatementEnhancementPostProcessor` class is responsible for enhancing textual statements
    associated with nodes. This class utilizes a language model and specific templates to improve
    the quality or formatting of the statements based on the provided chunk context. The enhancement
    is performed concurrently on multiple nodes for efficiency.

    Attributes:
        llm (Optional[LLMCache]): Language model cache used for enhancing statements. Defaults to
            `None`, in which case a default LLM configuration is used.
        max_concurrent (int): Maximum number of nodes to process concurrently. Defaults to 10.
        system_prompt (str): System-level prompt used as part of the enhancement template.
        user_prompt (str): User-level prompt used as part of the enhancement template.
        enhance_template (ChatPromptTemplate): Template used to structure the prompts for the
            language model.
    """

    llm: Optional[LLMCache] = Field(default=None)
    max_concurrent: int = Field(default=10)
    system_prompt: str = Field(default=ENHANCE_STATEMENT_SYSTEM_PROMPT)
    user_prompt: str = Field(default=ENHANCE_STATEMENT_USER_PROMPT)
    enhance_template: ChatPromptTemplate = Field(default=None)

    def __init__(
        self,
        llm:LLMCacheType=None,
        system_prompt: str = ENHANCE_STATEMENT_SYSTEM_PROMPT,
        user_prompt: str = ENHANCE_STATEMENT_USER_PROMPT,
        max_concurrent: int = 10
    ) -> None:
        """
        Initializes an instance of the class with an optional large language model (LLM)
        cache, a system prompt, a user prompt, and a configurable maximum number of
        concurrent executions. The system and user prompts initialize a chat template with
        predefined message roles and content.

        Args:
            llm: An optional large language model cache of type LLMCacheType. If none is
                provided, a new LLMCache instance is initialized with default settings.
            system_prompt: A string representing the system prompt used to initialize the
                chat template with a SYSTEM role message.
            user_prompt: A string representing the user prompt used to initialize the chat
                template with a USER role message.
            max_concurrent: An integer specifying the maximum number of concurrent
                executions allowed.
        """
        super().__init__()
        self.llm = llm if llm and isinstance(llm, LLMCache) else LLMCache(
            llm=llm or GraphRAGConfig.response_llm,
            enable_cache=GraphRAGConfig.enable_cache
        )
        self.max_concurrent = max_concurrent
        self.system_prompt = system_prompt
        self.user_prompt = user_prompt
        
        self.enhance_template = ChatPromptTemplate(message_templates=[
            ChatMessage(role=MessageRole.SYSTEM, content=system_prompt),
            ChatMessage(role=MessageRole.USER, content=user_prompt),
        ])

    def enhance_statement(self, node: NodeWithScore) -> NodeWithScore:
        """
        Enhances the statement of the input node by generating a modified version of the
        statement using a large language model (LLM). This method updates the node with
        the enhanced statement if the enhancement is successful. If an error occurs or
        the enhancement is unsuccessful, the original node is returned as-is.

        Args:
            node (NodeWithScore): The input node containing a text statement and
                associated metadata to enhance.

        Returns:
            NodeWithScore: A node object that includes the modified statement if
                successful, or the original node if the enhancement process fails.
        """
        try:
            response = self.llm.predict(
                prompt=self.enhance_template,
                statement=node.node.metadata['statement']['value'],
                context=node.node.metadata['chunk']['value'],
            )
            pattern = r'<modified_statement>(.*?)</modified_statement>'
            match = re.search(pattern, response, re.DOTALL)
            
            if match:
                enhanced_text = match.group(1).strip()
                new_node = TextNode(
                    text=enhanced_text,  
                    metadata={
                        'statement': node.node.metadata['statement'], 
                        'chunk': node.node.metadata['chunk'],
                        'source': node.node.metadata['source'],
                        'search_type': node.node.metadata.get('search_type')
                    }
                )
                return NodeWithScore(node=new_node, score=node.score)
            
            return node
            
        except Exception as e:
            logger.error(f"Error enhancing statement: {e}")
            return node

    def _postprocess_nodes(
        self,
        nodes: List[NodeWithScore],
        query_bundle: Optional[QueryBundle] = None,
    ) -> List[NodeWithScore]:
        """
        Post-processes a list of nodes by applying enhancements concurrently.

        This method takes a list of nodes, processes each node through the
        `enhance_statement` method, and returns the processed nodes as a list. It uses
        a thread pool to handle the parallel execution, improving performance.

        Args:
            nodes: A list of `NodeWithScore` objects that need to be processed.
            query_bundle: Optional; A `QueryBundle` object providing additional
                context or criteria for processing nodes.

        Returns:
            A list of `NodeWithScore` objects after being processed through the
            `enhance_statement` method.
        """
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
            return list(executor.map(self.enhance_statement, nodes))
        